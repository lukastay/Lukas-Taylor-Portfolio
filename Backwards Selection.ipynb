{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ac4214d-5ee2-4916-b767-2e21964d12f5",
   "metadata": {},
   "source": [
    "## Backwards Selection\n",
    "\n",
    "Problem:\n",
    "We have a lot of variables and we need to decide which to use in our regression model. \n",
    "\n",
    "Solution:\n",
    "Begin with a model that contains all variables. Then, one at a time, remove the least significant variable and record AIC, BIC, and R-Squared each time we do. R-Squared measures how much of the data's variation is explained by the model. AIC and BIC measure the opposite: they measure  unexplained variance in the regression model. But they also penalize a model for adding too many variables. At the end, we use the model with the best AIC, BIC, or R-Squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34a84900-8922-4042-b8e7-7a2405bf8b38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0     crim    zn  indus  chas    nox     rm   age     dis  rad  \\\n",
      "0           1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1   \n",
      "1           2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2   \n",
      "2           3  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2   \n",
      "3           4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3   \n",
      "4           5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3   \n",
      "\n",
      "   tax  ptratio   black  lstat  medv  \n",
      "0  296     15.3  396.90   4.98  24.0  \n",
      "1  242     17.8  396.90   9.14  21.6  \n",
      "2  242     17.8  392.83   4.03  34.7  \n",
      "3  222     18.7  394.63   2.94  33.4  \n",
      "4  222     18.7  396.90   5.33  36.2  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "\n",
    "raw0 = pd.read_csv('/Users/lukastaylor/Dropbox/Misc/Old Classes/MSEA Semester 1/ECON 5813/Data/Boston.csv')\n",
    "\n",
    "print(raw0.head())\n",
    "\n",
    "# define y and X\n",
    "raw0 = raw0.iloc[:,1:]\n",
    "#raw0np = raw0.values\n",
    "Y = raw0.iloc[:,-1] # -1 means the last one\n",
    "X = raw0.iloc[:,:-1] \n",
    "ncol=X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfcb7534-9071-4f90-830b-2df01e804efb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Would you like to have detailed information? (y/n) n\n",
      "What would criteria would you like to use? (AIC/BIC/Rsquared) bic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Done.\n",
      "\n",
      "FINAL MODEL INFORMATION\n",
      "\n",
      "Final Model Kept These Variables (in order of removal):\n",
      "Variable Numer #3 - nox\n",
      "Variable Numer #1 - indus\n",
      "Variable Numer #9 - ptratio\n",
      "Variable Numer #0 - zn\n",
      "Variable Numer #8 - tax\n",
      "Variable Numer #11 - lstat\n",
      "Variable Numer #4 - rm\n",
      "Variable Numer #7 - rad\n",
      "Variable Numer #10 - black\n",
      "Variable Numer #5 - age\n",
      "Variable Numer #12 - medv\n",
      "\n",
      "Final Model Removed These Variables:\n",
      "Variable Number #6 - dis\n",
      "Variable Number #2 - chas\n",
      "\n",
      "Final Model's BIC: 3076.4884435565546\n"
     ]
    }
   ],
   "source": [
    "detailed = input(\"Would you like to have detailed information? (y/n)\").lower()\n",
    "\n",
    "while True: \n",
    "    criteria = input(\"What would criteria would you like to use? (AIC/BIC/Rsquared)\").lower()\n",
    "    mode = {\"aic\":2,\"bic\":1,\"rsquared\":0,\"r-squared\":0}[criteria]\n",
    "    if mode in range(0,5): break\n",
    "    else: print(\"Error: invalid criteria\")\n",
    "\n",
    "# Code for backwards selection based on AIC, BIC, or R-Squared\n",
    "\n",
    "pcand = list(range(ncol)) # A list to keep track of the remaining predictors (i.e., not yet removed) at each iteration\n",
    "psel = list(range(ncol)) # A list to keep track of the selected predictors at each iteration (the order of the selected predictors)\n",
    "tb = np.zeros(ncol) # A vector to store the AIC, BIC, or R-Squared of the selected model (combination) at each iteration\n",
    "p = 0 # Iteration idex\n",
    "removelist, fittedlist = [], []\n",
    "\n",
    "while p != ncol: # Repeat below until the model excludes all the predictors\n",
    "    \n",
    "    tb0 = np.zeros((len(pcand),3)) # Store the Rsquared(s), AIC(s),  and BIC(s) of the models considered at each iteration\n",
    "    fittedlisttemp=[]\n",
    "\n",
    "    for i in range(0,len(pcand)):\n",
    "        \n",
    "        #Try removing a variable and store resulting AIC, BIC, or R-Squared \n",
    "        pseltemp=psel\n",
    "        pseltemp.remove(pcand[i])\n",
    "        res = sm.OLS(Y,  sm.add_constant(X.iloc[:, pseltemp])).fit()\n",
    "        tb0[i,:] = [res.rsquared, res.bic, res.aic]\n",
    "        fittedlisttemp.append(res)\n",
    "        psel.insert(0, pcand[i])\n",
    "        psel.sort()\n",
    "        \n",
    "        if detailed == \"y\": print(\"\\nTried removing the following variable:\", pcand[i], \"\\nincluded predictors:\", pseltemp, \"\\nAIC:\", tb0[i,2], \"BIC:\", tb0[i,1], \"R-Squared:\", tb0[i,0])\n",
    "    \n",
    "    # Find the regressor that results in the best criteria when added to the model\n",
    "    ind = np.argmax(tb0[:,mode]) if mode == 0 else np.argmin(tb0[:,mode])\n",
    "    psel.remove(pcand[ind])\n",
    "    p += 1\n",
    "    \n",
    "    if detailed == \"y\": print(\"\\nRemoving\", pcand[ind], \"\\nWe have gone through the while statement\", p, \"time(s)\\n--------------------------------\")\n",
    "    \n",
    "    removelist.append(pcand[ind])\n",
    "    pcand.remove(pcand[ind]) # Remove the selected regressor from pcand\n",
    "    tb[p-1] =  tb0[ind,mode] # Store the AIC, BIC, or R-Squared of the selected model at this iteration\n",
    "    fittedlist.append(fittedlisttemp[ind])\n",
    "\n",
    "#Finding Best Model\n",
    "best = np.argmax(tb)+1 if mode == 0 else np.argmin(tb)+1\n",
    "\n",
    "# Printing Results\n",
    "print(\"--------------------------\\nDone.\")\n",
    "if detailed == \"y\": x = [print(\"\\nMODEL NUMBER:\", i, \"\\nThis Model Removed Variable:\", removelist[i], \"\\nCriteria\", criteria.upper(), \"Value:\", tb[i]) for i in range(len(tb))]; x\n",
    "print(\"\\nFINAL MODEL INFORMATION\\n\\nFinal Model Kept These Variables (in order of removal):\")\n",
    "for i in removelist[best:]: print(\"Variable Numer #\"+str(i)+\" - \" + raw0.columns[i+1])\n",
    "print(\"\\nFinal Model Removed These Variables:\")\n",
    "for i in removelist[:best]: print(\"Variable Number #\"+str(i)+\" - \" + raw0.columns[i+1]) \n",
    "print(\"\"); print(str(\"Final Model's \"+criteria.upper())+str(\": \")+str(tb[best]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a14b3b-d644-4445-89fb-9db7220a3151",
   "metadata": {},
   "source": [
    "## Regression Of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16a3ceb2-41f6-48b8-b2e8-a3032a2e3912",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC is 3029.9965401943923 \n",
      "BIC is 3076.4884435565546 \n",
      "R-Squared is 0.7299149280771855 \n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   medv   R-squared:                       0.735\n",
      "Model:                            OLS   Adj. R-squared:                  0.730\n",
      "Method:                 Least Squares   F-statistic:                     137.5\n",
      "Date:                Sun, 23 Apr 2023   Prob (F-statistic):          6.70e-136\n",
      "Time:                        01:37:19   Log-Likelihood:                -1504.0\n",
      "No. Observations:                 506   AIC:                             3030.\n",
      "Df Residuals:                     495   BIC:                             3076.\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         36.6203      5.113      7.162      0.000      26.574      46.667\n",
      "crim          -0.1141      0.033     -3.453      0.001      -0.179      -0.049\n",
      "zn             0.0457      0.014      3.352      0.001       0.019       0.073\n",
      "nox          -16.4692      3.556     -4.631      0.000     -23.456      -9.482\n",
      "rm             3.8446      0.410      9.381      0.000       3.039       4.650\n",
      "dis           -1.5261      0.187     -8.155      0.000      -1.894      -1.158\n",
      "rad            0.3155      0.064      4.947      0.000       0.190       0.441\n",
      "tax           -0.0127      0.003     -3.737      0.000      -0.019      -0.006\n",
      "ptratio       -0.9784      0.130     -7.535      0.000      -1.234      -0.723\n",
      "black          0.0097      0.003      3.611      0.000       0.004       0.015\n",
      "lstat         -0.5281      0.048    -11.042      0.000      -0.622      -0.434\n",
      "==============================================================================\n",
      "Omnibus:                      192.780   Durbin-Watson:                   1.011\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              920.734\n",
      "Skew:                           1.632   Prob(JB):                    1.16e-200\n",
      "Kurtosis:                       8.746   Cond. No.                     1.47e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.47e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(\"AIC is\", fittedlist[best].aic, \"\\nBIC is\", fittedlist[best].bic, \"\\nR-Squared is\", fittedlist[best].rsquared_adj, \"\\n\")\n",
    "print(fittedlist[best].summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
