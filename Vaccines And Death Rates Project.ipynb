{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60c6540f-b043-4def-904a-436fde982605",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d672c8f-a858-4f49-af97-cb944204529b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   recip_county completeness_pct administered_dose1_recip  \\\n",
      "0  IN Randolph              98.5                    13253   \n",
      "1      MO Polk              91.3                    14811   \n",
      "2    TN Hardin              97.7                    12252   \n",
      "3    TN Cannon              97.7                     5576   \n",
      "4      NE Holt                91                      NaN   \n",
      "\n",
      "  administered_dose1_pop_pct administered_dose1_recip_5plus  \\\n",
      "0                       53.7                          13234   \n",
      "1                       46.1                          14795   \n",
      "2                       47.8                          12242   \n",
      "3                         38                           5571   \n",
      "4                        NaN                            NaN   \n",
      "\n",
      "  administered_dose1_recip_5pluspop_pct administered_dose1_recip_12plus  \\\n",
      "0                                    57                           13002   \n",
      "1                                    49                           14438   \n",
      "2                                  50.2                           12093   \n",
      "3                                  40.4                            5519   \n",
      "4                                   NaN                             NaN   \n",
      "\n",
      "  administered_dose1_recip_12pluspop_pct administered_dose1_recip_18plus  \\\n",
      "0                                   61.6                           12467   \n",
      "1                                   52.5                           13620   \n",
      "2                                   54.2                           11658   \n",
      "3                                   43.9                            5349   \n",
      "4                                    NaN                             NaN   \n",
      "\n",
      "  administered_dose1_recip_18pluspop_pct  ... census2019_18pluspop  \\\n",
      "0                                   65.3  ...                19105   \n",
      "1                                   54.8  ...                24857   \n",
      "2                                   57.1  ...                20420   \n",
      "3                                   46.4  ...                11528   \n",
      "4                                    NaN  ...                 7520   \n",
      "\n",
      "  census2019_65pluspop bivalent_booster_5plus bivalent_booster_5plus_pop_pct  \\\n",
      "0                 5134                   2327                             10   \n",
      "1                 5870                   3085                           10.2   \n",
      "2                 5982                   1474                            6.1   \n",
      "3                 2722                    394                            2.9   \n",
      "4                 2214                   1392                           14.8   \n",
      "\n",
      "  bivalent_booster_12plus bivalent_booster_12plus_pop_pct  \\\n",
      "0                    2317                              11   \n",
      "1                    3063                            11.1   \n",
      "2                    1466                             6.6   \n",
      "3                     391                             3.1   \n",
      "4                    1380                            16.5   \n",
      "\n",
      "  bivalent_booster_18plus bivalent_booster_18plus_pop_pct  \\\n",
      "0                    2291                              12   \n",
      "1                    3024                            12.2   \n",
      "2                    1455                             7.1   \n",
      "3                     384                             3.3   \n",
      "4                    1357                              18   \n",
      "\n",
      "  bivalent_booster_65plus bivalent_booster_65plus_pop_pct  \n",
      "0                    1564                            30.5  \n",
      "1                    1818                              31  \n",
      "2                     989                            16.5  \n",
      "3                     229                             8.4  \n",
      "4                     859                            38.8  \n",
      "\n",
      "[5 rows x 76 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "\n",
    "client = Socrata(\"data.cdc.gov\", None)\n",
    "\n",
    "results = client.get(\"8xkx-amqh\", date = \"2023-04-19T00:00:00.000\", limit = 99999999)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "raw0 = pd.DataFrame.from_records(results)\n",
    "for row in range(raw0.shape[0]): \n",
    "    seperated=raw0.loc[row,'recip_county'].split(' ')\n",
    "    toadd = raw0.loc[row,'recip_state'] + \" \"\n",
    "    for countyname in seperated:\n",
    "        if countyname != seperated[-1]: toadd += countyname\n",
    "        try:\n",
    "            if countyname != seperated[-2]: toadd += \" \"\n",
    "        except:\n",
    "            pass\n",
    "    raw0.loc[row,'recip_county'] = toadd\n",
    "raw0 = raw0.drop(['date', 'fips', 'mmwr_week','recip_state'], axis=1)\n",
    "print(raw0.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19f6176d-3a33-46ec-9341-9c4730e6bfb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "                county_name  all_deaths_total  covid_19_deaths_total  \\\n",
      "0              AK Anchorage              8401                    767   \n",
      "1              AK Anchorage              8401                    767   \n",
      "2              AK Anchorage              8401                    767   \n",
      "3  AK Fairbanks North Star               2011                    201   \n",
      "4  AK Fairbanks North Star               2011                    201   \n",
      "\n",
      "   non_hispanic_white  non_hispanic_black  non_hispanic_american_indian  \\\n",
      "0               0.570               0.045                         0.214   \n",
      "1               0.452               0.035                         0.254   \n",
      "2               0.564               0.052                         0.083   \n",
      "3               0.701               0.025                         0.182   \n",
      "4               0.612                 NaN                         0.264   \n",
      "\n",
      "   non_hispanic_asian  non_hispanic_nhopi  hispanic  other  \n",
      "0               0.058               0.031     0.032  0.049  \n",
      "1               0.111               0.076     0.039  0.033  \n",
      "2               0.098               0.031     0.095  0.077  \n",
      "3               0.020                 NaN     0.025  0.045  \n",
      "4                 NaN                 NaN       NaN  0.060  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import math \n",
    "from time import sleep\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import html5lib\n",
    "from pandas import json_normalize\n",
    "%matplotlib inline\n",
    "\n",
    "raw1 = pd.read_csv('https://data.cdc.gov/resource/k8wy-p9cg.csv?$query=SELECT%0A%20%20%60data_as_of%60%2C%0A%20%20%60start_week%60%2C%0A%20%20%60end_week%60%2C%0A%20%20%60state%60%2C%0A%20%20%60county_name%60%2C%0A%20%20%60urbanruralcode%60%2C%0A%20%20%60fipsstate%60%2C%0A%20%20%60fipscounty%60%2C%0A%20%20%60fipscode%60%2C%0A%20%20%60indicator%60%2C%0A%20%20%60all_deaths_total%60%2C%0A%20%20%60covid_19_deaths_total%60%2C%0A%20%20%60non_hispanic_white%60%2C%0A%20%20%60non_hispanic_black%60%2C%0A%20%20%60non_hispanic_american_indian%60%2C%0A%20%20%60non_hispanic_asian%60%2C%0A%20%20%60non_hispanic_nhopi%60%2C%0A%20%20%60hispanic%60%2C%0A%20%20%60other%60%2C%0A%20%20%60urbanruraldesc%60%2C%0A%20%20%60footnote%60%0AWHERE%20%60start_week%60%20%3D%20%222020-01-01T00%3A00%3A00%22%20%3A%3A%20floating_timestamp')\n",
    "for row in range(raw1.shape[0]): \n",
    "    seperated=raw1.loc[row,'county_name'].split(' ')\n",
    "    if len(seperated) == 2: raw1.loc[row,'county_name'] = raw1.loc[row,'state'] + \" \" + seperated[0]\n",
    "    else: \n",
    "        toadd = raw1.loc[row,'state'] + \" \"\n",
    "        for countyname in seperated:\n",
    "            if countyname != seperated[-1]: toadd += countyname\n",
    "            try:\n",
    "                if countyname != seperated[-2]: toadd += \" \"\n",
    "            except:\n",
    "                pass\n",
    "        raw1.loc[row,'county_name'] = toadd\n",
    "    \n",
    "raw1 = raw1.drop(['state','data_as_of', 'start_week', 'end_week','urbanruralcode','fipsstate','fipscounty','fipscode','indicator','urbanruraldesc','footnote'], axis=1)\n",
    "print(raw1.shape[0])\n",
    "print(raw1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61b4d3ad-d37d-4250-b7e7-0fc50e4255d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         NAME    POP\n",
      "0   MS Coahoma  22124\n",
      "1    MS Jasper  16383\n",
      "2     MS Jones  68098\n",
      "3  MS Walthall  14286\n",
      "4    MS Monroe  35252\n"
     ]
    }
   ],
   "source": [
    "key=\"7a1d4f2ad8bdd748802e4dda66a65fe3c9bef3df\"\n",
    "\n",
    "url='https://api.census.gov/data/2019/pep/charagegroups?get=NAME,POP&for=county:*&in=state:*&key='+key\n",
    "response = requests.get(url).json()\n",
    "raw2 = pd.DataFrame.from_dict(response)\n",
    "raw2.columns=raw2.iloc[0]\n",
    "raw2 = raw2.reset_index()\n",
    "raw2 = raw2.drop(raw2.index[0])\n",
    "\n",
    "StateAbbrev = {\"Alabama\": \"AL\",\"Alaska\": \"AK\",\"Arizona\": \"AZ\",\"Arkansas\": \"AR\",\"California\": \"CA\",\"Colorado\": \"CO\",\"Connecticut\": \"CT\",\"Delaware\": \"DE\",\"Florida\": \"FL\",\"Georgia\": \"GA\",\"Hawaii\": \"HI\",\"Idaho\": \"ID\",\"Illinois\": \"IL\",\"Indiana\": \"IN\",\"Iowa\": \"IA\",\"Kansas\": \"KS\",\"Kentucky\": \"KY\",\"Louisiana\": \"LA\",\"Maine\": \"ME\",\"Maryland\": \"MD\",\"Massachusetts\": \"MA\",\"Michigan\": \"MI\",\"Minnesota\": \"MN\",\"Mississippi\": \"MS\",\"Missouri\": \"MO\",\"Montana\": \"MT\",\"Nebraska\": \"NE\",\"Nevada\": \"NV\",\"New Hampshire\": \"NH\",\"New Jersey\": \"NJ\",\"New Mexico\": \"NM\",\"New York\": \"NY\",\"North Carolina\": \"NC\",\"North Dakota\": \"ND\",\"Ohio\": \"OH\",\"Oklahoma\": \"OK\",\"Oregon\": \"OR\",\"Pennsylvania\": \"PA\",\"Rhode Island\": \"RI\",\"South Carolina\": \"SC\",\"South Dakota\": \"SD\",\"Tennessee\": \"TN\",\"Texas\": \"TX\",\"Utah\": \"UT\",\"Vermont\": \"VT\",\"Virginia\": \"VA\",\"Washington\": \"WA\",\"West Virginia\": \"WV\",\"Wisconsin\": \"WI\",\"Wyoming\": \"WY\",\"District of Columbia\": \"DC\",\"American Samoa\": \"AS\",\"Guam\": \"GU\",\"Northern Mariana Islands\": \"MP\",\"Puerto Rico\": \"PR\",\"United States Minor Outlying Islands\": \"UM\",\"U.S. Virgin Islands\": \"VI\",}\n",
    "raw2 = raw2.reset_index()\n",
    "for row in range(raw2.shape[0]):\n",
    "    seperated=raw2.loc[row,\"NAME\"].split(' ')\n",
    "    if not seperated[-1] in StateAbbrev.keys(): toadd = raw2.loc[row,\"NAME\"]\n",
    "    else:\n",
    "        toadd = StateAbbrev[seperated[len(seperated)-1]] + \" \" + seperated[0]\n",
    "        for i in seperated[1:-1]:\n",
    "            if i != \"County\" and i != \"County,\": toadd += \" \" + i\n",
    "    \n",
    "    raw2.loc[row,'NAME'] = toadd\n",
    "    \n",
    "raw2 = raw2.drop(['index','level_0','state','county'], axis=1)\n",
    "\n",
    "print(raw2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58388ae3-779e-422f-8659-ef3d9a394089",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CTYNAME  POPESTIMATE  POPEST_MALE  POPEST_FEM  UNDER5_TOT  UNDER5_MALE  \\\n",
      "0  AL Autauga        58877        28734       30143        3480         1812   \n",
      "1  AL Baldwin       233140       113612      119528       12176         6348   \n",
      "2  AL Barbour        25180        13373       11807        1342          694   \n",
      "3     AL Bibb        22223        11901       10322        1219          594   \n",
      "4   AL Blount        59081        29400       29681        3474         1808   \n",
      "\n",
      "   UNDER5_FEM  AGE513_TOT  AGE513_MALE  AGE513_FEM  ...  AGE7579_FEM  \\\n",
      "0        1668        7042         3606        3436  ...         1058   \n",
      "1        5828       25601        13101       12500  ...         4892   \n",
      "2         648        2675         1322        1353  ...          532   \n",
      "3         625        2210         1159        1051  ...          376   \n",
      "4        1666        6910         3480        3430  ...         1168   \n",
      "\n",
      "   AGE8084_TOT  AGE8084_MALE  AGE8084_FEM  AGE85PLUS_TOT  AGE85PLUS_MALE  \\\n",
      "0         1145           495          650            876             334   \n",
      "1         5475          2503         2972           4173            1721   \n",
      "2          563           236          327            474             154   \n",
      "3          448           185          263            354             119   \n",
      "4         1273           575          698           1025             377   \n",
      "\n",
      "   AGE85PLUS_FEM  MEDIAN_AGE_TOT  MEDIAN_AGE_MALE  MEDIAN_AGE_FEM  \n",
      "0            542            39.2             38.0            40.3  \n",
      "1           2452            43.8             42.6            44.9  \n",
      "2            320            40.8             39.0            43.9  \n",
      "3            235            40.3             38.6            42.7  \n",
      "4            648            41.1             40.4            41.9  \n",
      "\n",
      "[5 rows x 91 columns]\n"
     ]
    }
   ],
   "source": [
    "raw3 = pd.read_csv('https://www2.census.gov/programs-surveys/popest/datasets/2020-2021/counties/asrh/cc-est2021-agesex-all.csv', encoding='latin-1')\n",
    "raw3 = raw3.loc[raw3['YEAR'] == 2]\n",
    "raw3 = raw3.reset_index()\n",
    "for row in range(raw3.shape[0]):\n",
    "    seperated=raw3.loc[row,'CTYNAME'].split(' ')\n",
    "    try:\n",
    "        raw3.loc[row,'CTYNAME'] = StateAbbrev[raw3.loc[row,'STNAME']] + \" \" + seperated[0]\n",
    "    except:\n",
    "        raw3.drop([row])\n",
    "raw3 = raw3.drop(['SUMLEV','STATE','COUNTY','STNAME','index','YEAR'], axis=1)\n",
    "print(raw3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ca467bf-7335-456b-a3cb-ec03b8624ab6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Area_name  Rural-urban_Continuum_Code_2003  Urban_Influence_Code_2003  \\\n",
      "2  AL Autauga                              2.0                        2.0   \n",
      "3  AL Baldwin                              4.0                        5.0   \n",
      "4  AL Barbour                              6.0                        6.0   \n",
      "5     AL Bibb                              1.0                        1.0   \n",
      "6   AL Blount                              1.0                        1.0   \n",
      "\n",
      "   Rural-urban_Continuum_Code_2013  Urban_Influence_Code_2013  POVALL_2020  \\\n",
      "2                              2.0                        2.0       6242.0   \n",
      "3                              3.0                        2.0      20189.0   \n",
      "4                              6.0                        6.0       5548.0   \n",
      "5                              1.0                        1.0       3549.0   \n",
      "6                              1.0                        1.0       7525.0   \n",
      "\n",
      "   CI90LBALL_2020  CI90UBALL_2020  PCTPOVALL_2020  CI90LBALLP_2020  ...  \\\n",
      "2          4930.0          7554.0            11.2              8.8  ...   \n",
      "3         15535.0         24843.0             8.9              6.8  ...   \n",
      "4          4210.0          6886.0            25.5             19.3  ...   \n",
      "5          2712.0          4386.0            17.8             13.6  ...   \n",
      "6          6034.0          9016.0            13.1             10.5  ...   \n",
      "\n",
      "   CI90UB517P_2020  MEDHHINC_2020  CI90LBINC_2020  CI90UBINC_2020  POV04_2020  \\\n",
      "2             19.3        67565.0         59132.0         75998.0         NaN   \n",
      "3             16.1        71135.0         66540.0         75730.0         NaN   \n",
      "4             47.2        38866.0         33510.0         44222.0         NaN   \n",
      "5             28.6        50907.0         43627.0         58187.0         NaN   \n",
      "6             20.5        55203.0         47820.0         62586.0         NaN   \n",
      "\n",
      "   CI90LB04_2020  CI90UB04_2020  PCTPOV04_2020  CI90LB04P_2020  CI90UB04P_2020  \n",
      "2            NaN            NaN            NaN             NaN             NaN  \n",
      "3            NaN            NaN            NaN             NaN             NaN  \n",
      "4            NaN            NaN            NaN             NaN             NaN  \n",
      "5            NaN            NaN            NaN             NaN             NaN  \n",
      "6            NaN            NaN            NaN             NaN             NaN  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import xlrd\n",
    "import openpyxl\n",
    "\n",
    "raw4 = pd.read_excel('https://www.ers.usda.gov/webdocs/DataFiles/48747/PovertyEstimates.xlsx?v=6499.5', skiprows=[0,1,2,3])\n",
    "#raw4 = raw4.drop([0,1,2,3])\n",
    "droplist=[]\n",
    "raw4 = raw4.reset_index()\n",
    "for row in range(raw4.shape[0]):\n",
    "    seperated=raw4.loc[row,'Area_name'].split(' ')\n",
    "    if \"County\" in seperated:\n",
    "        try:\n",
    "            raw4.loc[row,'Area_name'] = raw4.loc[row,'Stabr'] + \" \" + seperated[0]\n",
    "        except:\n",
    "            droplist.append(row)\n",
    "    else: \n",
    "        droplist.append(row)\n",
    "\n",
    "raw4 = raw4.drop(droplist, axis=0)\n",
    "raw4 = raw4.drop(['index','FIPS_code','Stabr'], axis=1)\n",
    "print(raw4.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f14d25fb-52ce-4430-bbeb-f05809552a02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import math \n",
    "from time import sleep\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import html5lib\n",
    "%matplotlib inline\n",
    "\n",
    "columns=[]\n",
    "columns.append(['raw1',['covid_19_deaths_total']])\n",
    "\n",
    "iteration=0\n",
    "colcount=0\n",
    "allcolumns=[]\n",
    "for columnlists in [i for i in [raw0.columns[1:],raw2.columns[1:],raw3.columns[1:],raw4.columns[1:]]]: \n",
    "    \n",
    "    if iteration == 1: iteration = 2\n",
    "    columnstemp=[]\n",
    "    for column in columnlists:\n",
    "        columnstemp.append(str(column))\n",
    "        colcount+=1\n",
    "    \n",
    "    columns.append([str(\"raw\"+str(iteration)), columnstemp])\n",
    "    for columntemp in columnstemp: allcolumns.append(str(columntemp))\n",
    "    \n",
    "    iteration+=1\n",
    "    \n",
    "#print(columns)\n",
    "df = pd.DataFrame(columns = allcolumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7db09f74-1369-45e6-8370-a36f0c41c043",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1000, 1, 1000, 2, 3220, 3, 3143, 4, 3007]\n"
     ]
    }
   ],
   "source": [
    "print([0,raw0.shape[0],1,raw1.shape[0],2,raw2.shape[0],3,raw3.shape[0],4,raw4.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fccecb0a-d2bc-4ea9-bb56-533eb0e0e2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 1000 of 3220\n",
      "finished 2000 of 3220\n",
      "finished 3000 of 3220\n",
      "  completeness_pct administered_dose1_recip administered_dose1_pop_pct  \\\n",
      "0             none                     none                       none   \n",
      "1             none                     none                       none   \n",
      "2             none                     none                       none   \n",
      "3             none                     none                       none   \n",
      "4             none                     none                       none   \n",
      "\n",
      "  administered_dose1_recip_5plus administered_dose1_recip_5pluspop_pct  \\\n",
      "0                           none                                  none   \n",
      "1                           none                                  none   \n",
      "2                           none                                  none   \n",
      "3                           none                                  none   \n",
      "4                           none                                  none   \n",
      "\n",
      "  administered_dose1_recip_12plus administered_dose1_recip_12pluspop_pct  \\\n",
      "0                            none                                   none   \n",
      "1                            none                                   none   \n",
      "2                            none                                   none   \n",
      "3                            none                                   none   \n",
      "4                            none                                   none   \n",
      "\n",
      "  administered_dose1_recip_18plus administered_dose1_recip_18pluspop_pct  \\\n",
      "0                            none                                   none   \n",
      "1                            none                                   none   \n",
      "2                            none                                   none   \n",
      "3                            none                                   none   \n",
      "4                            none                                   none   \n",
      "\n",
      "  administered_dose1_recip_65plus  ... CI90UB517P_2020 MEDHHINC_2020  \\\n",
      "0                            none  ...            66.1       30047.0   \n",
      "1                            none  ...            37.1       42806.0   \n",
      "2                            none  ...            33.7       49115.0   \n",
      "3                            none  ...            45.9       30992.0   \n",
      "4                            none  ...            26.7       49114.0   \n",
      "\n",
      "  CI90LBINC_2020 CI90UBINC_2020 POV04_2020 CI90LB04_2020 CI90UB04_2020  \\\n",
      "0        25799.0        34295.0        NaN           NaN           NaN   \n",
      "1        36257.0        49355.0        NaN           NaN           NaN   \n",
      "2        43771.0        54459.0        NaN           NaN           NaN   \n",
      "3        26361.0        35623.0        NaN           NaN           NaN   \n",
      "4        43028.0        55200.0        NaN           NaN           NaN   \n",
      "\n",
      "  PCTPOV04_2020 CI90LB04P_2020 CI90UB04P_2020  \n",
      "0           NaN            NaN            NaN  \n",
      "1           NaN            NaN            NaN  \n",
      "2           NaN            NaN            NaN  \n",
      "3           NaN            NaN            NaN  \n",
      "4           NaN            NaN            NaN  \n",
      "\n",
      "[5 rows x 197 columns]\n"
     ]
    }
   ],
   "source": [
    "def whichdf(column):\n",
    "            \n",
    "    for dfandcolumn in columns:\n",
    "\n",
    "        if column in dfandcolumn[1]: return dfandcolumn[0]\n",
    "    \n",
    "raw0 = raw0.reset_index()\n",
    "raw1 = raw1.reset_index()\n",
    "raw2 = raw2.reset_index()\n",
    "raw3 = raw3.reset_index()\n",
    "raw4 = raw4.reset_index()\n",
    "\n",
    "def addrow():\n",
    "    \n",
    "    global df\n",
    "    global row\n",
    "    \n",
    "    rowtoadd=[]\n",
    "    \n",
    "    #replace with correct df (the one that's the longest)\n",
    "    location = str(raw2.loc[row,'NAME'])\n",
    "    \n",
    "    #You can remove the longest df's search\n",
    "    raw0row = \"empty\"\n",
    "    for row2 in range(raw0.shape[0]):\n",
    "        location2 = str(raw0.loc[row2,'recip_county'])\n",
    "        if location2 == location: raw0row = row2\n",
    "    raw1row = \"empty\"\n",
    "    for row2 in range(raw1.shape[0]):\n",
    "        location2 = str(raw1.loc[row2,'county_name'])\n",
    "        if location2 == location: raw1row = row2\n",
    "    raw3row = \"empty\"\n",
    "    for row2 in range(raw3.shape[0]):\n",
    "        location2 = str(raw3.loc[row2,'CTYNAME'])\n",
    "        if location2 == location: raw3row = row2\n",
    "    raw4row = \"empty\"\n",
    "    for row2 in range(raw4.shape[0]):\n",
    "        location2 = str(raw4.loc[row2,'Area_name'])\n",
    "        if location2 == location: raw4row = row2\n",
    "    \n",
    "    for column in list(df.columns):\n",
    "        \n",
    "        column=str(column)\n",
    "        \n",
    "        correctdf = whichdf(column)\n",
    "        \n",
    "        if correctdf == \"raw0\" and not raw0row == \"empty\": rowtoadd.append(raw0.loc[raw0row, column])\n",
    "        elif correctdf == \"raw1\" and not raw1row == \"empty\": rowtoadd.append(raw1.loc[raw1row, column])\n",
    "        elif correctdf == \"raw2\": rowtoadd.append(raw2.loc[row, column])\n",
    "        elif correctdf == \"raw3\" and not raw3row == \"empty\": rowtoadd.append(raw3.loc[raw3row, column])\n",
    "        elif correctdf == \"raw4\" and not raw4row == \"empty\": rowtoadd.append(raw4.loc[raw4row, column])\n",
    "        else: rowtoadd.append(\"none\")\n",
    "        \n",
    "    df.loc[len(df)] = rowtoadd\n",
    "    \n",
    "    if row % 1000 == 0 and row != 0: print(\"finished\", row, \"of\", raw2.shape[0])\n",
    "\n",
    "#replace with longest df\n",
    "for row in range(raw2.shape[0]-1): addrow()\n",
    "\n",
    "print(df.head())\n",
    "#df.to_pickle(\"df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dea3e4-b101-496e-b01f-45928d649630",
   "metadata": {},
   "source": [
    "## Initial OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705ba014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.compat import lzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "formulas = ['deathspercap ~ dose1', 'deathspercap ~ series', 'deathspercap ~ booster', 'deathspercap ~ dose1 + percapincome', 'deathspercap ~ series + percapincome', 'deathspercap ~ booster + percapincome']\n",
    "\n",
    "def olsmaker(formula):\n",
    "    \n",
    "    OLS = smf.ols(formula, data=df).fit()\n",
    "    \n",
    "    print(\"FORMULA:\", formula, \"\\n\\nAIC is\", OLS.aic, \"\\nBIC is\", OLS.bic, \"\\nR-Squared is\", OLS.rsquared_adj, \"\\n\"); print(OLS.summary()); print(\"\\n\")\n",
    "    \n",
    "    fig = sm.graphics.plot_fit(OLS,1, vlines=False); plt.show()\n",
    "    fig = sm.graphics.plot_partregress_grid(OLS); plt.show()\n",
    "    fig = sm.graphics.plot_ccpr_grid(OLS); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80319227-7c5a-47fa-b535-4d610b729cf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "olsmaker(formulas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8332c4a-acb6-4f19-b4dc-62a1cd1e6447",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "olsmaker(formulas[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ef565d-320b-4b30-9d52-0a72bd72cffa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "olsmaker(formulas[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4a82d6-1cc5-4ee0-a180-e86e2573e102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "olsmaker(formulas[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c76d4e-5f3c-4974-8332-21e4c72e2ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "olsmaker(formulas[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b367c39c-a2d2-44f6-89f1-9bb207ccf146",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "olsmaker(formulas[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f6f8af",
   "metadata": {},
   "source": [
    "## LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3486ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcopy = df.iloc[:,1:]\n",
    "Y = dfcopy.loc[:, \"deathspercap\"]\n",
    "Xlist = []\n",
    "\n",
    "droplist = [[\"dose1\",[\"deaths\",\"deathspercap\",\"county\",\"index\", \"deaths\", \"series\", \"booster\",\"pop\"]],[\"series\",[\"deathspercap\",\"deaths\",\"county\",\"index\", \"deaths\", \"dose1\", \"booster\",\"pop\"]],[\"booster\",[\"deathspercap\",\"deaths\",\"county\",\"index\", \"deaths\", \"dose1\", \"series\",\"pop\"]]]\n",
    "\n",
    "for typeanddrops in droplist:\n",
    "    \n",
    "    xtype = typeanddrops[0]\n",
    "    dfcopy = df\n",
    "    dfcopy = dfcopy.drop(typeanddrops[1], axis=1)\n",
    "    \n",
    "    Xlist.append([xtype, dfcopy, list(dfcopy.columns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19854d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import lasso_path\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import StandardScaler #usually, we want to standardize to put in terms of standard deviations. to minimize iimpact of measurement\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LassoLarsCV, LassoLarsIC\n",
    "import time\n",
    "\n",
    "SC = StandardScaler()\n",
    "\n",
    "Xns = []\n",
    "for X in Xlist:\n",
    "    SC.fit(X[1]) \n",
    "    Xns.append(SC.transform(X[1])) #use these statistic to standardize. Xn contains standardized x variables\n",
    "\n",
    "def lasso(Xnum):\n",
    "    print(\"Primary X Value:\", Xlist[Xnum][0])\n",
    "    # Use \"eps\" to specify the length and density of the grid (eps = alpha_min / alpha_max)\n",
    "    eps=2.220446049250313e-16\n",
    "    alphas_lasso, coefs_lasso, _ = lasso_path(Xns[Xnum], Y, eps = eps, max_iter=1000000000) #first, we need to select lamda values\n",
    "    #eps is one of the parameters to use for finding which lamda values to use\n",
    "    #eps chooses smallest lamda value\n",
    "    #eps = lamda min/ lamda max\n",
    "    #can use n_alphas to select number of alphas in regularization path\n",
    "    #alphas_lasso is lamdas that were used, coef is lasso estimates\n",
    "    # Display the solution path\n",
    "    plt.figure(figsize=(8, 7), dpi=80) #define figure size\n",
    "    colors = cycle(['b', 'r', 'g', 'c','m', 'y', 'k']) #coloring lines. iterates colors. k is black\n",
    "\n",
    "    # Take the log of the alpha values to adjust the scale of X-axis\n",
    "    log_alphas_lasso = np.log10(alphas_lasso) #taking log of lamdas\n",
    "    \n",
    "    varname = Xlist[Xnum][2]\n",
    "    # Use a for-loop to plot several paths on a figure \n",
    "    for coef_l, c, vn in zip(coefs_lasso, colors, varname): #zip holds these functions temperarly. coeff lasso is parameter estimate, colors is the colors, varname is variable name.\n",
    "        l1 = plt.plot(log_alphas_lasso, coef_l, c=c, label=vn) #drawing lines. coefff lasso starts with first row. \n",
    "        #in first iteragtion, selects first row of this object. then first item in color. variable name will be variable name.\n",
    "\n",
    "    plt.xlabel('Log(alpha)')\n",
    "    plt.ylabel('Coefficient Estimtes')\n",
    "    plt.title('Lasso Solution Path')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    #log alpha negative because they're small numbers.\n",
    "    \n",
    "def lassopick(Xnum, cvoraicbic):\n",
    "    \n",
    "    print(\"Primary X Value:\", Xlist[Xnum][0])\n",
    "    varname = Xlist[Xnum][2]\n",
    "    \n",
    "    eps=2.220446049250313e-16\n",
    "    \n",
    "    if cvoraicbic == \"cv\":\n",
    "        print(\"PICKING BEST MODEL BASED ON CROSS VALIDATION\\n\")\n",
    "        t1 = time.time() # Get the current time\n",
    "        lascv = LassoLarsCV(cv=5).fit(Xns[Xnum], Y) #how many chunks you break the data into. use 5 or 10 folds, include x and y\n",
    "        t_lasso_lars_cv = time.time() - t1 # Calculate running time\n",
    "\n",
    "        # Display the results\n",
    "        lascv_log_alphas = np.log10(lascv.cv_alphas_ + eps)  #result variable.cv alphas is lamdas. alpha (singular) is lamda that is optimal. eps is different from what we used before. eps is just small number. include zero because taki9ng log of zero creates error\n",
    "        lascv_log_alpha = np.log10(lascv.alpha_) #log of lamda that minimized MSE\n",
    "        # Caution: lascv.alphas contains the alpha at the lowest MSE whereas lascv.cv_alphas_ contains the set of alphas used in the path\n",
    "        # The smallest value in lascv.cv_alphas_ is 0 so we add eps (a small number) to avoid log(0)\n",
    "\n",
    "        plt.figure(figsize=(8, 7), dpi=80)\n",
    "        plt.plot(lascv_log_alphas, lascv.mse_path_.mean(axis=1), 'k',\n",
    "                 label='Average of the MSEs over the Folds', linewidth=2)\n",
    "        plt.axvline(lascv_log_alpha, linestyle='--', color='k', #add verticle line at optimal lamda\n",
    "                    label='alpha selected by CV')\n",
    "\n",
    "        plt.legend()\n",
    "\n",
    "        plt.xlabel('Log(alpha)')\n",
    "        plt.ylabel('Mean Square Error')\n",
    "        plt.title('Model Selection by Cross Validation (train time: %.2fs)'\n",
    "                  % t_lasso_lars_cv)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Best Alpha (Based on Cross Validation):\", lascv_log_alpha)\n",
    "        print(\"\\nBest Model (Based on Cross Validation):\")\n",
    "        for varnum in range(len(varname)): print(varname[varnum],lascv.coef_[varnum])\n",
    "    \n",
    "    if cvoraicbic == \"aicbic\":\n",
    "        print(\"PICKING BEST MODEL BASED ON AIC AND BIC\\n\")\n",
    "        \n",
    "        t1 = time.time() # Get the current time\n",
    "        lascv = LassoLarsCV(cv=5).fit(Xns[Xnum], Y) #how many chunks you break the data into. use 5 or 10 folds, include x and y\n",
    "        t_lasso_lars_cv = time.time() - t1 # Calculate running time\n",
    "\n",
    "        # Display the results\n",
    "        lascv_log_alphas = np.log10(lascv.cv_alphas_ + eps)  #result variable.cv alphas is lamdas. alpha (singular) is lamda that is optimal. eps is different from what we used before. eps is just small number. include zero because taki9ng log of zero creates error\n",
    "        lascv_log_alpha = np.log10(lascv.alpha_) #log of lamda that minimized MSE\n",
    "        # Caution: lascv.alphas contains the alpha at the lowest MSE whereas lascv.cv_alphas_ contains the set of alphas used in the path\n",
    "        # The smallest value in lascv.cv_alphas_ is 0 so we add eps (a small number) to avoid log(0)\n",
    "\n",
    "\n",
    "        lasic_bic = LassoLarsIC(criterion='bic').fit(Xns[Xnum], Y) #specify which criterian. plug in x and y. store results in these two variables\n",
    "        lasic_aic = LassoLarsIC(criterion='aic').fit(Xns[Xnum], Y)\n",
    "\n",
    "        # Display results\n",
    "        # make a fn to produce figures with the same features repeatedly\n",
    "        def plot_ic_criterion(model, name, color): \n",
    "            alpha_ = model.alpha_ + eps #optimal lamda\n",
    "            alphas_ = model.alphas_ + eps #lamdas that were used in this function\n",
    "            criterion_ = model.criterion_ # BIC or AIC values over the alpha values\n",
    "            plt.plot(np.log10(alphas_), criterion_, '--', color=color,\n",
    "                     linewidth=3, label='%s' % name)\n",
    "            plt.axvline(np.log10(alpha_), color=color, linewidth=3, #adding vertical line\n",
    "                        label='$\\lambda$ selected by %s ' % name)\n",
    "            plt.xlabel('Log($\\lambda$)')\n",
    "            plt.ylabel('Criterion Value')\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(8, 7), dpi=80)\n",
    "        plot_ic_criterion(lasic_aic, 'AIC', 'b') #line is AIC result\n",
    "        plot_ic_criterion(lasic_bic, 'BIC', 'r') #line is BIC result\n",
    "        plt.legend()\n",
    "        plt.title('Model Selection by Information Criteria')\n",
    "        plt.show()\n",
    "\n",
    "        print(\"\\n\\nBest Model (Based on AIC):\")\n",
    "        for varnum in range(len(varname)): print(varname[varnum],lasic_aic.coef_[varnum])\n",
    "        print(\"\\n\\nBest Model (Based on BIC):\")\n",
    "        for varnum in range(len(varname)): print(varname[varnum],lasic_bic.coef_[varnum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2f1e68-6cf3-4252-9e81-f0ccf15f8071",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lasso(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5bc961-2af8-49de-97f7-652ef64a0c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "lassopick(0, \"cv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f060ec1-812a-4f1d-891d-6faf6b27eae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lassopick(0, \"aicbic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec337b45-20e3-401d-98a0-6184ee968505",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lasso(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1580a56a-f293-4865-95fc-f2506818aa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lassopick(1, \"cv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc2aaf9-6884-418c-bdff-7be36d8e7c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "lassopick(1, \"aicbic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75fcd61-4fc5-4b2f-bd10-12ae6472d026",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lasso(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009a0b6a-c2b4-48dd-8f8a-bb9e16936244",
   "metadata": {},
   "outputs": [],
   "source": [
    "lassopick(2, \"cv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0c141b-fbf8-4d7e-9492-95565c285518",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lassopick(2, \"aicbic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8063a78a",
   "metadata": {},
   "source": [
    "## Forwards Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f330c9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwards(Xlistnum, criteria):\n",
    "    \n",
    "    global selected\n",
    "             \n",
    "    Xvalues=Xlist[Xlistnum]\n",
    "    mode = {\"AIC\":2,\"BIC\":1,\"R-Squared\":0}[criteria]\n",
    "    \n",
    "    print(\"TYPE:\", Xvalues[0], \"CRITERIA:\", criteria, \"\\n\")\n",
    "    \n",
    "    X = Xvalues[1]\n",
    "    Xnp = Xvalues[1].values\n",
    "    ncol=X.shape[1]\n",
    "    pcand = list(range(ncol)) # A list to keep track of the remaining predictors (i.e., not yet added) at each iteration\n",
    "    psel = [] # A list to keep track of the selected predictors at each iteration (the order of the selected predictors)\n",
    "    tb = np.zeros(ncol) # A vector to store the BIC of the selected model (combination) at each iteration\n",
    "    p = 0 # Iteration idex\n",
    "    addedlist=[]\n",
    "\n",
    "    while len(psel) != ncol: # Repeat below until the model includes all the predictors\n",
    "        \n",
    "        tb0 = np.zeros((len(pcand),3)) # Store the Rsquare(s) and BIC(s) of the models considered at each iteration\n",
    "\n",
    "        for i in range(0,len(pcand)):\n",
    "            psel0 = psel + [pcand[i]] # \"psel0\" is a temporary version of psel which includes one of the predictors in pcan and those in psel\n",
    "            # Caution: \"+\" combines two lists, but not a list and an integer (i.e pcan[i])\n",
    "            XX = Xnp[:,psel0]\n",
    "            XX = sm.add_constant(XX)\n",
    "            model = sm.OLS(Y, XX)\n",
    "            res = model.fit()\n",
    "            tb0[i,:] = [res.rsquared, res.bic, res.aic]\n",
    "\n",
    "        ind = np.argmax(tb0[:,mode]) if mode == 0 else np.argmin(tb0[:,mode])\n",
    "        addedlist.append(pcand[ind])\n",
    "        psel = psel + [pcand[ind]] # Add the selected regressor to psel\n",
    "        pcand.remove(pcand[ind]) # Remove the selected regressor from pcand\n",
    "        tb[p] =  tb0[ind,1] # Store the BIC of the selected model at this iteration\n",
    "        p += 1\n",
    "        \n",
    "    #[print(\"\\nMODEL NUMBER:\", i, \"\\nThis Model Added Variable:\", X.columns[addedlist[i]], \"\\nCriteria\", criteria.upper(), \"Value:\", tb[i]) for i in range(len(tb))]\n",
    "        \n",
    "    best = np.argmax(tb)+1 if mode == 0 else np.argmin(tb)+1\n",
    "    \n",
    "    selected = [X.columns[i] for i in list(addedlist[:best])]\n",
    "    print(\"SELECTED VARIABLES:\", [i for i in selected])\n",
    "\n",
    "    formula = 'deathspercap ~ '\n",
    "    for variable in selected:\n",
    "        formula += \" +\" + variable\n",
    "\n",
    "    OLS = smf.ols(formula, data=df).fit()\n",
    "    print(\"AIC is\", OLS.aic)\n",
    "    print(\"BIS is\", OLS.bic)\n",
    "    print(\"R-Squared is\", OLS.rsquared_adj)\n",
    "    print(OLS.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c3b942-f60c-4f76-a3ba-1a3f78a2d98a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forwards(0,\"AIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65aed7f-5e8c-4c5a-adbe-f98d605f47b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forwards(0,\"BIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa5868-219b-46f7-b7a9-9e1e8f6d2000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forwards(0,\"R-Squared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef76aa2-1b78-4df4-b144-fc7ebbbfcaeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forwards(1,\"AIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8c77ca-5b7e-4272-a5ba-08f36d970dcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forwards(1,\"BIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abc857f-5d83-4bc0-b94a-2e64b0c647fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forwards(1,\"R-Squared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110b152d-bbc8-4de9-a72b-05619f0799de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forwards(2,\"AIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16af9e40-4b37-431d-84ce-fd57f3054368",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forwards(2,\"BIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaae4f4-a3ad-4e80-ad56-056ae95e1108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forwards(2,\"R-Squared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1b8740-9763-4f83-85c1-2420dc435855",
   "metadata": {},
   "source": [
    "## Backward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cb4204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backwards(Xnum, criteria):\n",
    "    \n",
    "    Xvalues = Xlist[Xnum]\n",
    "    print(\"TYPE:\", Xvalues[0], \"\\n\")\n",
    "        \n",
    "    X = Xvalues[1]\n",
    "    Xnp = Xvalues[1].values\n",
    "    ncol=X.shape[1]\n",
    "\n",
    "    pcand = list(range(ncol)) # A list to keep track of the remaining predictors (i.e., not yet removed) at each iteration\n",
    "    psel = list(range(ncol)) # A list to keep track of the selected predictors at each iteration (the order of the selected predictors)\n",
    "    tb = np.zeros(ncol) # A vector to store the AIC, BIC, or R-Squared of the selected model (combination) at each iteration\n",
    "    p = 0 # Iteration idex\n",
    "    removelist, fittedlist = [], []\n",
    "\n",
    "    mode = {\"AIC\":2,\"BIC\":1,\"R-Squared\":0}[criteria]\n",
    "\n",
    "    print(\"SELECTING MODEL BASED ON:\", criteria)\n",
    "\n",
    "    while p != ncol: # Repeat below until the model excludes all the predictors\n",
    "\n",
    "        tb0 = np.zeros((len(pcand),3)) # Store the Rsquared(s), AIC(s),  and BIC(s) of the models considered at each iteration\n",
    "        fittedlisttemp=[]\n",
    "\n",
    "        for i in range(0,len(pcand)):\n",
    "\n",
    "            #Try removing a variable and store resulting AIC, BIC, or R-Squared \n",
    "            pseltemp=psel\n",
    "            pseltemp.remove(pcand[i])\n",
    "            res = sm.OLS(Y, sm.add_constant(X.iloc[:, pseltemp])).fit()\n",
    "            tb0[i,:] = [res.rsquared, res.bic, res.aic]\n",
    "            fittedlisttemp.append(res)\n",
    "            psel.insert(0, pcand[i])\n",
    "            psel.sort()\n",
    "\n",
    "            #print(\"\\nTried removing the following variable:\", pcand[i], \"\\nincluded predictors:\", pseltemp, \"\\nAIC:\", tb0[i,2], \"BIC:\", tb0[i,1], \"R-Squared:\", tb0[i,0])\n",
    "\n",
    "        # Find the regressor that results in the best criteria when added to the model\n",
    "        ind = np.argmax(tb0[:,mode]) if mode == 0 else np.argmin(tb0[:,mode])\n",
    "        psel.remove(pcand[ind])\n",
    "        p += 1\n",
    "\n",
    "        #print(\"\\nRemoving\", pcand[ind], \"\\nWe have gone through the while statement\", p, \"time(s)\\n--------------------------------\")\n",
    "\n",
    "        removelist.append(pcand[ind])\n",
    "        pcand.remove(pcand[ind]) # Remove the selected regressor from pcand\n",
    "        tb[p-1] =  tb0[ind,mode] # Store the AIC, BIC, or R-Squared of the selected model at this iteration\n",
    "        fittedlist.append(fittedlisttemp[ind])\n",
    "\n",
    "    #Finding Best Model\n",
    "    best = np.argmax(tb)+1 if mode == 0 else np.argmin(tb)+1\n",
    "\n",
    "    #[print(\"\\nMODEL NUMBER:\", i, \"\\nThis Model Removed Variable:\", removelist[i], \"\\nCriteria\", criteria.upper(), \"Value:\", tb[i]) for i in range(len(tb))]\n",
    "\n",
    "    selected = [X.columns[i] for i in list(removelist[best:])]\n",
    "\n",
    "    formula = 'deathspercap ~ '\n",
    "    for variable in selected:\n",
    "        formula += \" +\" + variable\n",
    "\n",
    "    OLS = smf.ols(formula, data=df).fit()\n",
    "    print(\"AIC is\", OLS.aic)\n",
    "    print(\"BIS is\", OLS.bic)\n",
    "    print(\"R-Squared is\", OLS.rsquared_adj)\n",
    "    print(OLS.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dcf99c-5f67-4db8-b3f8-b35842ad76e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "backwards(0, \"AIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181918ba-8ae2-4b52-bd2c-e341638c0c76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "backwards(0, \"BIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427f32e7-3a98-4094-a737-beabc16287d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "backwards(0, \"R-Squared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e2d45d-b3ba-4466-b650-fa12a52f82e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "backwards(1, \"AIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28531f95-2912-436f-b8d6-768403b69447",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "backwards(1, \"BIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9370de9-3cdf-459d-96bb-3a14edc6033e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "backwards(1, \"R-Squared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475538b3-e21a-4d84-b3d9-482f8e0f3406",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "backwards(2, \"AIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a78311f-41f2-4de3-a8cf-d6ee8622a21b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "backwards(2, \"BIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d14178-2072-4d74-8a3f-138277492795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "backwards(2, \"R-Squared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba521073",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0b1415",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xclustering=df[['dose1', 'series','booster']]\n",
    "Xclustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f24421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "KMres = KMeans(n_clusters=3, random_state=0).fit(Xclustering)\n",
    "y_pred = KMres.predict(Xclustering)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(Xclustering.iloc[:,0], Xclustering.iloc[:,1], c=y_pred) \n",
    "\n",
    "    \n",
    "plt.xlabel('Dose 1 Percentage ',fontsize = 15)\n",
    "plt.ylabel('Series Percentage',fontsize = 15)\n",
    "plt.title('Groups by Dose 1 Percentage and Series Percentage',fontsize = 15)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cd2c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 18))\n",
    "\n",
    "for i in range(1,5):\n",
    "    plt.subplot(2,2,i)\n",
    "    KMres = KMeans(n_clusters=i+1, random_state=0).fit(Xclustering)\n",
    "    y_pred = KMres.predict(Xclustering)\n",
    "\n",
    "    plt.scatter(Xclustering.iloc[:,0], Xclustering.iloc[:,1], c=y_pred) \n",
    "    plt.xlabel('Dose 1 Percentage ',fontsize = 15)\n",
    "    plt.ylabel('Series Percentage',fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab28853a",
   "metadata": {},
   "source": [
    "### Dendogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d94b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "\n",
    "Z = hierarchy.linkage(Xclustering, 'complete') \n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "hierarchy.dendrogram(Z,)\n",
    "                     \n",
    "plt.title('Hierarchical Clustering on Vaccine Administered Type', size=20)           \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1faba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 10))\n",
    "hierarchy.dendrogram(Z,\n",
    "                     truncate_mode='level', # The other option: 'lastp' - show only p branches\n",
    "                     p = 5, # number of clusters\n",
    "                     leaf_rotation=90,\n",
    "                     leaf_font_size=12,\n",
    "                     \n",
    "                     )\n",
    "                     \n",
    "plt.title('Hierarchical Clustering on Vaccine Administered Type with five clusters', size=20)          \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53538c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "i=1\n",
    "\n",
    "for hiertype in ['single', 'complete', 'average', 'weighted', 'centroid', 'ward']:\n",
    "    \n",
    "    plt.subplot(2,3,i)\n",
    "    \n",
    "    Z = hierarchy.linkage(Xclustering, hiertype) \n",
    "\n",
    "    hierarchy.dendrogram(Z, leaf_rotation=90, leaf_font_size=.2, )\n",
    "\n",
    "    plt.title(hiertype, size=7)\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2995eff2-b553-4241-b855-96bffe88c1b4",
   "metadata": {},
   "source": [
    "### Running regression based off dummy groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978651e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def clusterreg(num):\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=num, random_state=0).fit(Xclustering)\n",
    "    labels = list(kmeans.labels_)\n",
    "\n",
    "    dftemp = df\n",
    "    dftemp['label'] = labels\n",
    "    groups = dftemp.groupby('label')\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    #ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "    for name, group in groups:\n",
    "        ax.plot(group.dose1, group.series, marker='o', linestyle='', ms=2, label=name)\n",
    "    ax.legend()\n",
    "    plt.xlabel('Dose 1 Percentage ',fontsize = 15)\n",
    "    plt.ylabel('Series Percentage',fontsize = 15)\n",
    "    plt.title('Groups by Dose 1 Percentage and Series Percentage',fontsize = 15)\n",
    "    plt.show()\n",
    "    \n",
    "    OLS3 = smf.ols(\"deathspercap ~ label\", data=dftemp).fit()\n",
    "    print(\"\\n\\n\\n\\nAIC is\", OLS3.aic, \"\\nBIS is\", OLS3.bic, \"\\nR-Squared is\", OLS3.rsquared_adj, \"\\n\")\n",
    "    print(OLS3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36613cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterreg(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a871adb-4f08-4e31-886d-3eccdb210719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clusterreg(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
